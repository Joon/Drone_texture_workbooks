{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate tile classes per H5 file\n",
    "\n",
    "Once the Ilastik classifier has classified images, it produces per-pixel probabilities as an H5 file. This workbook loads those per-pixel probabilities, and then samples each tile to obtain the class for all the pixels in the tile, so that the tile can be compared with the ground truth data as a whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Determine how many pixels to sample per tile for a statistically significant finding\n",
    "\n",
    "Use the Cochran formula to determine a statistically significant sample of pixels. Then trim that down to the total population of a texture tile (900 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_size(tile_size):\n",
    "    # Calculate statistically significant test sample size\n",
    "\n",
    "    # Z score for a 95% confidence (from Z table)\n",
    "    Z_score = 1.96\n",
    "    # Calculate with a 5% margin of error\n",
    "    margin_of_error = 0.05\n",
    "\n",
    "\n",
    "    # Some selected expected population percentages\n",
    "    population_with_attribute_water = 0.09\n",
    "    population_with_attribute_foliage = 0.876\n",
    "    population_with_attribute_road = 0.027\n",
    "    population_with_attribute_building = 0.006\n",
    "    \n",
    "    # Number of samples is the size of a square tile\n",
    "    N = tile_size ** 2\n",
    "\n",
    "    required_samples = 0\n",
    "\n",
    "    # Calc for all population percentages, output all values. We will pick the largest one\n",
    "    for p in [population_with_attribute_water, \n",
    "              population_with_attribute_foliage, population_with_attribute_road, \n",
    "              population_with_attribute_building]:\n",
    "        q = 1 - p\n",
    "        # Calc required samples for an unlimited population\n",
    "        n_0 = ((Z_score ** 2) * p * q) / (margin_of_error ** 2)\n",
    "        # Now reduce this unbounded required sample count down by the known population \n",
    "        # per tile (900 pixels)\n",
    "        n = n_0 / (1 + ((n_0 - 1) / N))\n",
    "        if (n > required_samples):\n",
    "            required_samples = round(n) + (1 if round(n) != n else 0)\n",
    "\n",
    "    return required_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate the class per tile in each probability file, save as csv\n",
    "\n",
    "Each image will have a statistically significant sample of pixels chosen per tile (uniformly distributed), and the probabilities of those pixels will be aggregated to provide the class of the tile.\n",
    "\n",
    "A CSV file will be saved per image with the class of all the tiles in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def calc_class(foliage, water, building, road):\n",
    "    if foliage > 0.5:\n",
    "        return 'foliage'\n",
    "    if water > 0.5:\n",
    "        return 'water'\n",
    "    if building > 0.5:\n",
    "        return 'building'\n",
    "    if road > 0.5:\n",
    "        return 'road'\n",
    "    return 'unknown'\n",
    "\n",
    "def calc_tile_classes(img_data_arr, tile_size):    \n",
    "    # The image data is in a 3 dimensional array. Dimension 1 is the Y pixel value, 2 is the X pixel value \n",
    "    # and Z contains an array of the 4 classes probabilities\n",
    "    names = ['y', 'x', 'z']\n",
    "    # Create an index for the dataframe\n",
    "    index = pd.MultiIndex.from_product([range(s) for s in img_data_arr.shape], names=names)\n",
    "    # create the dataframe itself\n",
    "    image_df = pd.DataFrame({'A': img_data_arr.flatten()}, index=index)['A']\n",
    "    # Reformat into a 4 column frame with the 2 column index by unpacking the array\n",
    "    image_df = image_df.unstack(level='z').swaplevel().sort_index()\n",
    "    # Set the column names for the probabilities\n",
    "    image_df.columns = ['A', 'B', 'C', 'D']\n",
    "\n",
    "    y_size, x_size, z_size = img_data_arr.shape\n",
    "    required_samples = sample_size(tile_size)\n",
    "    # Now build a matrix of sample pixels across the image, the array will contain the 30 pixel tile number\n",
    "    # and a uniformly distributed random selection of pixels from that tile\n",
    "    sample_pixel_arr = []\n",
    "    all_items = itertools.product(np.asarray(range(int(x_size / tile_size))), np.asarray(range(int(y_size/tile_size))))\n",
    "    for x, y in all_items:\n",
    "        x_s = np.asarray([int(round(x[0])) for x in np.random.uniform((x * tile_size), (x * tile_size) + \n",
    "                                                                      tile_size, (required_samples, 1))])\n",
    "        y_s = np.asarray([int(round(x[0])) for x in np.random.uniform((y * tile_size), (y * tile_size) + \n",
    "                                                                      tile_size, (required_samples, 1))])\n",
    "        sample_pixel_arr.append(list(zip(x_s, y_s, itertools.repeat(x), itertools.repeat(y))))\n",
    "\n",
    "    # Convert the sample array to a dataframe for joining\n",
    "    sample_matrix = np.asarray(sample_pixel_arr)\n",
    "    sample_arr = np.reshape(sample_matrix, (sample_matrix.shape[0] * sample_matrix.shape[1], \n",
    "                                            sample_matrix.shape[2]))\n",
    "    sample_df = pd.DataFrame(sample_arr)\n",
    "    sample_df.columns = ['x', 'y', 'tile_x', 'tile_y']\n",
    "    sample_df.set_index(['x', 'y'], inplace=True)\n",
    "    \n",
    "    # Join the sample pixels with the original probabilities frame to get the probabilities for each sample pixel\n",
    "    sample_pixels = pd.merge(left=sample_df, right=image_df, left_on=['x', 'y'], right_on=['x', 'y'])\n",
    "\n",
    "    # Sum all probabilities to give a total probability value for each category\n",
    "    aggregated_samples = sample_pixels.groupby(['tile_x', 'tile_y'], as_index=False).agg(\n",
    "        {\"A\": \"sum\", \"B\": \"sum\", \"C\": \"sum\", \"D\": \"sum\"})\n",
    "    \n",
    "    aggregated_samples = aggregated_samples.fillna(0)\n",
    "    \n",
    "    sample_counts = [0] * len(aggregated_samples)        \n",
    "    sample_counts = sample_counts + aggregated_samples['A']\n",
    "    sample_counts = sample_counts + aggregated_samples['B']\n",
    "    sample_counts = sample_counts + aggregated_samples['C']\n",
    "    sample_counts = sample_counts + aggregated_samples['D']   \n",
    "        \n",
    "    # Divide total probability by number of samples to give a probability percentage per tile\n",
    "    aggregated_samples['A'] = aggregated_samples['A'] / sample_counts\n",
    "    aggregated_samples['B'] = aggregated_samples['B'] / sample_counts\n",
    "    aggregated_samples['C'] = aggregated_samples['C'] / sample_counts\n",
    "    aggregated_samples['D'] = aggregated_samples['D'] / sample_counts    \n",
    "    \n",
    "    # Now calculate the class by inspecting the probability percentage. If any of the categories is \n",
    "    # above 50% that is considered to be the predicted  category of that tile\n",
    "    aggregated_samples.loc[:,'tile_class'] = pd.Series('unsure', index=aggregated_samples.index)\n",
    "    aggregated_samples.loc[aggregated_samples['A'] > 0.5, 'tile_class'] = pd.Series('foliage', index=aggregated_samples.index)\n",
    "    aggregated_samples.loc[aggregated_samples['B'] > 0.5, 'tile_class'] = pd.Series('water', index=aggregated_samples.index)\n",
    "    aggregated_samples.loc[aggregated_samples['C'] > 0.5, 'tile_class'] = pd.Series('building', index=aggregated_samples.index)\n",
    "    aggregated_samples.loc[aggregated_samples['D'] > 0.5, 'tile_class'] = pd.Series('road', index=aggregated_samples.index)\n",
    "    #aggregated_samples['tile_class'] = df.apply(lambda x: calc_class(x['A'], x['B'], x['C'], x['D']), axis=1)\n",
    "\n",
    "    return aggregated_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../ilastik/TestingData\\test\\DJI_0099200_Probabilities.h5 orig width 3840 classified width 3840 tile size 30.0\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../../TestPredictions/Ilastik/test_DJI_0099200_Probabilities.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b0efc4f582ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m               'tile size', tile_size)    \n\u001b[0;32m     26\u001b[0m         \u001b[0mtile_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_tile_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mtile_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../TestPredictions/Ilastik/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpre\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3201\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3202\u001b[0m         )\n\u001b[1;32m-> 3203\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             )\n\u001b[0;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../../TestPredictions/Ilastik/test_DJI_0099200_Probabilities.csv'"
     ]
    }
   ],
   "source": [
    "import re \n",
    "from PIL import Image\n",
    "\n",
    "probability_filenames = glob.glob('../../ilastik/TestingData/*/*.h5', recursive=True)\n",
    "for file in probability_filenames:\n",
    "    head_tail = os.path.split(file)\n",
    "    folder = os.path.basename(head_tail[0])\n",
    "    filename = head_tail[1]\n",
    "    pre, ext = os.path.splitext(filename)\n",
    "    \n",
    "    image_file_portion = re.search(\"DJI\\_[0-9]*\", pre).group()\n",
    "    search_folder = '../../Texture_Repo/Donegal_Rural_Terrain_Textures/Test_Images/*/' + image_file_portion + '.jpg'\n",
    "    match_files = glob.glob(search_folder)\n",
    "    if len(match_files) == 0:\n",
    "        print('ERROR: Source file not found for', pre)\n",
    "    else:\n",
    "        orig_image = Image.open(match_files[0])\n",
    "        original_width = orig_image.width\n",
    "        f = h5py.File(file, 'r')\n",
    "        img_data_arr = np.asarray(f['exported_data'])                \n",
    "        classified_width = img_data_arr.shape[1]\n",
    "        tile_size = (classified_width / original_width) * 30\n",
    "        print('Processing', file, 'orig width', original_width, 'classified width', classified_width, \n",
    "              'tile size', tile_size)    \n",
    "        tile_data = calc_tile_classes(img_data_arr, tile_size)\n",
    "        tile_data.to_csv('../../TestPredictions/Ilastik/' + folder + '_' + pre + '.csv', index=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
